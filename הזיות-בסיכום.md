

# הזיות בסיכום


אחד השימושים המרכזיים של AI הוא סיכום: לקחת טקסט ארוך ומשעמם של בני אדם, ולסכם אותו לטקסט קצר וברור! למרבה הצער, ל AI יש המון הזיות גם בנושא הזה.
יש ארבעה שאלות לשאול פה:
1. כמה נפוצות הזיות בסיכומי AI?
2. האם רוב ההזיות הם _הזיות חיצוניות_ (ה AI ממציא תוכן סתם ככה ומכניס אותו לסיכום) או _הזיות פנימיות_ (הזיות שבהן AI מערבב בין דברים בטקסט המקורי, כמו לערבב בין השמות יוסף כהן וחיים לוי וליצור את השם יוסף לוי, כשהוא לא הופיע בכלל בטקסט)?
3. כמה מההזיות הן *עובדתיות*? (הזיות שבהן המידע לא מדויק, אבל עדיין נכון בסך הכל).
4. האם יש דרך אוטומטית לזהות הזיות, או שאדם צריך לבדוק את זה?
There are 4 questions to answer here:
1. How frequently do generative AI models hallucinate content?
2. Do models hallucinate by manipulating the information present in the input document (intrinsic hallucinations), or by adding information they "made up" (extrinsic hallucinations)?
3. How much hallucinated content is _factual_ (Not accurate, but still correct)?
4. Are there automatic means of measuring these hallucinations?
Here are the conclusions:
1. Hallucinations happen frequently. In almost 70% of single-sentence summerizations
2. Extrinsic hallucinations are much more common (About 90% of the hallucinations) than intinsic hallucinations
-  These two answers mean that most summarizations include hallucinations, and most of them are just made up and not factual.